{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-05 08:41:14.728678: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-05 08:41:14.728773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-05 08:41:15.080660: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-05 08:41:15.818479: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-05 08:41:19.275516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"IMSyPP/hate_speech_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9942781925201416}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipe(\"I love you\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import threading\n",
    "import json\n",
    "from kafka import KafkaProducer\n",
    "from kafka.errors import KafkaError\n",
    "# SKLearn libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -sSOL https://downloads.apache.org/kafka/3.3.2/kafka_2.13-3.3.2.tgz\n",
    "# !tar -xzf kafka_2.13-3.3.2.tgz-\n",
    "\n",
    "# !./kafka/bin/zookeeper-server-start.sh -daemon ./kafka/config/zookeeper.properties \n",
    "# !./kafka/bin/kafka-server-start.sh -daemon\n",
    "# !echo \"Waiting for 10 secs until kafka and zookeeper services are up and running\"\n",
    "# !sleep 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !./kafka/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1 --topic cancer-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_callback(exc):\n",
    "      raise Exception('Error while sending data to kafka: {0}'.format(str(exc)))\n",
    "\n",
    "\n",
    "def write_to_kafka(topic_name, items):\n",
    "      count=0\n",
    "      producer = KafkaProducer(bootstrap_servers=['127.0.0.1:29092'])\n",
    "      for message, key in items:\n",
    "        print(message.encode('utf-8'))\n",
    "        producer.send(topic_name,\n",
    "                      key=key.encode('utf-8'),\n",
    "                      value=message.encode('utf-8')).add_errback(error_callback)\n",
    "        count+=1\n",
    "      producer.flush()\n",
    "      print(\"Wrote {0} messages into topic: {1}\".format(count, topic_name))\n",
    "\n",
    "\n",
    "def decode_kafka_item(message):\n",
    "#     print (\"%s:%d:%d: key=%s value=%s\" % (message.topic, message.partition,\n",
    "#                                           message.offset, message.key,\n",
    "#                                           message.value))\n",
    "    return message.value.decode('utf-8')\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytchat\n",
    "\n",
    "# chat = pytchat.create(video_id=\"uIx8l2xlYVY\")\n",
    "# while chat.is_alive():\n",
    "#     for c in chat.get().sync_items():\n",
    "#         print(f\"{c.datetime} [{c.author.name}]- {c.message}\")\n",
    "#         write_to_kafka('youtube', [(c.message, c.author.name)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate speech detected!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pybloom_live import BloomFilter\n",
    "\n",
    "df = pd.read_csv('hurtlex_EN.tsv', sep='\\t')\n",
    "\n",
    "grouped = df.groupby('category')\n",
    "grouped.head()\n",
    "\n",
    "\n",
    "# Create a Bloom filter with an appropriate size and false positive rate\n",
    "bloom_filter = BloomFilter(capacity=df.shape[0], error_rate=0.001)\n",
    "\n",
    "# Add hate speech terms to the Bloom filter\n",
    "hate_speech_terms = df[\"lemma\"]\n",
    "for term in hate_speech_terms:\n",
    "    bloom_filter.add(term)\n",
    "\n",
    "\n",
    "def detect_hate_speech(text):\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        if token in bloom_filter:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Test the hate speech detection function\n",
    "text = \"I will love you\"\n",
    "if detect_hate_speech(text):\n",
    "    print(\"Hate speech detected!\")\n",
    "else:\n",
    "    print(\"No hate speech detected.\")\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "def read_from_kafka(topic_name):\n",
    "    consumer = KafkaConsumer(\n",
    "        topic_name,\n",
    "        auto_offset_reset='earliest',\n",
    "        bootstrap_servers=['127.0.0.1:29092'],\n",
    "        consumer_timeout_ms=10000\n",
    "    )\n",
    "    # Continuously listen for messages\n",
    "    while True:\n",
    "        records = consumer.poll(timeout_ms=1000, max_records=500)\n",
    "        print(\"Received {0} messages from topic: {1}\".format(len(records), topic_name))\n",
    "        for record in records:\n",
    "            for message in records[record]:\n",
    "                decoded_msg = decode_kafka_item(message)\n",
    "                print(detect_hate_speech(decoded_msg))\n",
    "# read_from_kafka('youtube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 05:14:29.776 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/codespace/.local/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-03-05 05:14:29.777 `st.experimental_memo` is deprecated. Please use the new command `st.cache_data` instead, which has the same behavior. More information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).\n",
      "2024-03-05 05:14:29.778 No runtime found, using MemoryCacheStorageManager\n",
      "2024-03-05 05:14:29.779 No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 92\u001b[0m\n\u001b[1;32m     90\u001b[0m st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Detailed Data View\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m st\u001b[38;5;241m.\u001b[39mdataframe(df)\n\u001b[0;32m---> 92\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time  # to simulate a real time data, time loop\n",
    "\n",
    "import numpy as np  # np mean, np random\n",
    "import pandas as pd  # read csv, df manipulation\n",
    "import plotly.express as px  # interactive charts\n",
    "import streamlit as st  # 🎈 data web app development\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Real-Time Data Science Dashboard\",\n",
    "    page_icon=\"✅\",\n",
    "    layout=\"wide\",\n",
    ")\n",
    "\n",
    "# read csv from a github repo\n",
    "dataset_url = \"https://raw.githubusercontent.com/Lexie88rus/bank-marketing-analysis/master/bank.csv\"\n",
    "\n",
    "# read csv from a URL\n",
    "@st.experimental_memo\n",
    "def get_data() -> pd.DataFrame:\n",
    "    return pd.read_csv(dataset_url)\n",
    "\n",
    "df = get_data()\n",
    "\n",
    "# dashboard title\n",
    "st.title(\"Real-Time / Live Data Science Dashboard\")\n",
    "\n",
    "# top-level filters\n",
    "job_filter = st.selectbox(\"Select the Job\", pd.unique(df[\"job\"]))\n",
    "\n",
    "# creating a single-element container\n",
    "placeholder = st.empty()\n",
    "\n",
    "# dataframe filter\n",
    "df = df[df[\"job\"] == job_filter]\n",
    "\n",
    "# near real-time / live feed simulation\n",
    "for seconds in range(200):\n",
    "\n",
    "    df[\"age_new\"] = df[\"age\"] * np.random.choice(range(1, 5))\n",
    "    df[\"balance_new\"] = df[\"balance\"] * np.random.choice(range(1, 5))\n",
    "\n",
    "    # creating KPIs\n",
    "    avg_age = np.mean(df[\"age_new\"])\n",
    "\n",
    "    count_married = int(\n",
    "        df[(df[\"marital\"] == \"married\")][\"marital\"].count()\n",
    "        + np.random.choice(range(1, 30))\n",
    "    )\n",
    "\n",
    "    balance = np.mean(df[\"balance_new\"])\n",
    "\n",
    "    with placeholder.container():\n",
    "\n",
    "        # create three columns\n",
    "        kpi1, kpi2, kpi3 = st.columns(3)\n",
    "\n",
    "        # fill in those three columns with respective metrics or KPIs\n",
    "        kpi1.metric(\n",
    "            label=\"Age ⏳\",\n",
    "            value=round(avg_age),\n",
    "            delta=round(avg_age) - 10,\n",
    "        )\n",
    "        \n",
    "        kpi2.metric(\n",
    "            label=\"Married Count 💍\",\n",
    "            value=int(count_married),\n",
    "            delta=-10 + count_married,\n",
    "        )\n",
    "        \n",
    "        kpi3.metric(\n",
    "            label=\"A/C Balance ＄\",\n",
    "            value=f\"$ {round(balance,2)} \",\n",
    "            delta=-round(balance / count_married) * 100,\n",
    "        )\n",
    "\n",
    "        # create two columns for charts\n",
    "        fig_col1, fig_col2 = st.columns(2)\n",
    "        with fig_col1:\n",
    "            st.markdown(\"### First Chart\")\n",
    "            fig = px.density_heatmap(\n",
    "                data_frame=df, y=\"age_new\", x=\"marital\"\n",
    "            )\n",
    "            st.write(fig)\n",
    "            \n",
    "        with fig_col2:\n",
    "            st.markdown(\"### Second Chart\")\n",
    "            fig2 = px.histogram(data_frame=df, x=\"age_new\")\n",
    "            st.write(fig2)\n",
    "\n",
    "        st.markdown(\"### Detailed Data View\")\n",
    "        st.dataframe(df)\n",
    "        time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
