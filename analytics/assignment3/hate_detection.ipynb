{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-05 08:41:14.728678: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-05 08:41:14.728773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-05 08:41:15.080660: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-05 08:41:15.818479: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-05 08:41:19.275516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"IMSyPP/hate_speech_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9942781925201416}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipe(\"I love you\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import threading\n",
    "import json\n",
    "from kafka import KafkaProducer\n",
    "from kafka.errors import KafkaError\n",
    "# SKLearn libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_callback(exc):\n",
    "      raise Exception('Error while sending data to kafka: {0}'.format(str(exc)))\n",
    "\n",
    "\n",
    "def write_to_kafka(topic_name, items):\n",
    "      count=0\n",
    "      producer = KafkaProducer(bootstrap_servers=['127.0.0.1:29092'])\n",
    "      for message, key in items:\n",
    "        print(message.encode('utf-8'))\n",
    "        producer.send(topic_name,\n",
    "                      key=key.encode('utf-8'),\n",
    "                      value=message.encode('utf-8')).add_errback(error_callback)\n",
    "        count+=1\n",
    "      producer.flush()\n",
    "      print(\"Wrote {0} messages into topic: {1}\".format(count, topic_name))\n",
    "\n",
    "\n",
    "def decode_kafka_item(message):\n",
    "#     print (\"%s:%d:%d: key=%s value=%s\" % (message.topic, message.partition,\n",
    "#                                           message.offset, message.key,\n",
    "#                                           message.value))\n",
    "    return message.value.decode('utf-8')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate speech detected!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pybloom_live import BloomFilter\n",
    "\n",
    "df = pd.read_csv('hurtlex_EN.tsv', sep='\\t')\n",
    "\n",
    "grouped = df.groupby('category')\n",
    "grouped.head()\n",
    "\n",
    "\n",
    "# Create a Bloom filter with an appropriate size and false positive rate\n",
    "bloom_filter = BloomFilter(capacity=df.shape[0], error_rate=0.001)\n",
    "\n",
    "# Add hate speech terms to the Bloom filter\n",
    "hate_speech_terms = df[\"lemma\"]\n",
    "for term in hate_speech_terms:\n",
    "    bloom_filter.add(term)\n",
    "\n",
    "\n",
    "def detect_hate_speech(text):\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        if token in bloom_filter:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Test the hate speech detection function\n",
    "text = \"I will love you\"\n",
    "if detect_hate_speech(text):\n",
    "    print(\"Hate speech detected!\")\n",
    "else:\n",
    "    print(\"No hate speech detected.\")\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# producer.py\n",
    "\n",
    "import pytchat\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def error_callback(exc):\n",
    "    raise Exception('Error while sending data to kafka: {0}'.format(str(exc)))\n",
    "\n",
    "\n",
    "def write_to_kafka(topic_name, items):\n",
    "    count = 0\n",
    "    producer = KafkaProducer(bootstrap_servers=['127.0.0.1:29092'])\n",
    "    for message, key in items:\n",
    "        print(message.encode('utf-8'))\n",
    "        producer.send(topic_name,\n",
    "                      key=key.encode('utf-8'),\n",
    "                      value=message.encode('utf-8')).add_errback(error_callback)\n",
    "        count += 1\n",
    "    producer.flush()\n",
    "    print(\"Wrote {0} messages into topic: {1}\".format(count, topic_name))\n",
    "\n",
    "\n",
    "def decode_kafka_item(message):\n",
    "    print (\"%s:%d:%d: key=%s value=%s\" % (message.topic, message.partition,\n",
    "                                          message.offset, message.key,\n",
    "                                          message.value))\n",
    "    return message.value.decode('utf-8')\n",
    "\n",
    "import time\n",
    "\n",
    "chat = pytchat.create(video_id=\"XuSaNXRNwEw\")\n",
    "while chat.is_alive():\n",
    "    for c in chat.get().sync_items():\n",
    "        print(f\"{c.datetime} [{c.author.name}]- {c.message}\")\n",
    "        time.sleep(1)\n",
    "        write_to_kafka('youtube', [(c.message, c.author.name)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise.py\n",
    "\n",
    "import time  # to simulate a real time data, time loop\n",
    "\n",
    "import numpy as np  # np mean, np random\n",
    "import pandas as pd  # read csv, df manipulation\n",
    "import plotly.express as px  # interactive charts\n",
    "import streamlit as st  # ðŸŽˆ data web app development\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pybloom_live import BloomFilter\n",
    "from kafka import KafkaConsumer\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"IMSyPP/hate_speech_en\")\n",
    "\n",
    "\n",
    "df_speech = pd.read_csv('hurtlex_EN.tsv', sep='\\t')\n",
    "\n",
    "grouped = df_speech.groupby('category')\n",
    "grouped.head()\n",
    "\n",
    "# Create a Bloom filter with an appropriate size and false positive rate\n",
    "bloom_filter = BloomFilter(capacity=df_speech.shape[0], error_rate=0.001)\n",
    "\n",
    "# Add hate speech terms to the Bloom filter\n",
    "hate_speech_terms = df_speech[\"lemma\"]\n",
    "for term in hate_speech_terms:\n",
    "    bloom_filter.add(term)\n",
    "\n",
    "\n",
    "def detect_hate_speech(text)-> bool:\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        if token in bloom_filter:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Test the hate speech detection function\n",
    "text = \"I will love you\"\n",
    "if detect_hate_speech(text):\n",
    "    print(\"Hate speech detected!\")\n",
    "else:\n",
    "    print(\"No hate speech detected.\")\n",
    "\n",
    "def decode_kafka_item(message):\n",
    "    print (\"%s:%d:%d: key=%s value=%s\" % (message.topic, message.partition,\n",
    "                                          message.offset, message.key,\n",
    "                                          message.value))\n",
    "    return message.value.decode('utf-8')\n",
    "\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Real-Time Hate Speech Detection Dashboard\",\n",
    "    page_icon=\"âœ…\",\n",
    "    layout=\"wide\",\n",
    "    )\n",
    "# dashboard title\n",
    "st.title(\"Real-Time / Live Data Youtube Chat Stream Dashboard\")\n",
    "\n",
    "\n",
    "# [{'label': 'LABEL_2', 'score': 0.6886570453643799}]\n",
    "#make a mapping\n",
    "# 0 - acceptable\n",
    "# 1 - inappropriate\n",
    "# 2 - offensive\n",
    "# 3 - violent\n",
    "# LABEL_0\n",
    "label_to_category = {\n",
    "    \"LABEL_0\": \"acceptable\",\n",
    "    \"LABEL_1\": \"inappropriate\",\n",
    "    \"LABEL_2\": \"offensive\",\n",
    "    \"LABEL_3\": \"violent\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_from_kafka(topic_name):\n",
    "    consumer = KafkaConsumer(\n",
    "        topic_name,\n",
    "        auto_offset_reset='latest',\n",
    "        bootstrap_servers=['127.0.0.1:29092'],\n",
    "        consumer_timeout_ms=10000\n",
    "    )\n",
    "    # Continuously listen for messages\n",
    "    placeholder = st.empty()\n",
    "\n",
    "    hate_speech_count = 0\n",
    "\n",
    "    acceptable_count = 0\n",
    "    inappropriate_count = 0\n",
    "    offensive_count = 0\n",
    "    violent_count = 0\n",
    "\n",
    "    avg_bloom_execution_time = 0\n",
    "    avg_model_execution_time = 0\n",
    "\n",
    "    bloom_execution_total_time = 0\n",
    "    model_execution_total_time = 0\n",
    "\n",
    "\n",
    "    plt.style.use('dark_background') \n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    x = np.array([time.time()])\n",
    "    y = np.array([0])\n",
    "    line, = ax.plot(x, y)\n",
    "\n",
    "\n",
    "    ax.set_xlim(x[0], x[0] + 600)\n",
    "    ax.set_ylim(0, 10)\n",
    "\n",
    "    the_plot = st.pyplot(plt)\n",
    "\n",
    "    line.set_xdata(x)\n",
    "    line.set_ydata(y)\n",
    "\n",
    "    #put titles\n",
    "    plt.title('Hate Speech Count Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Hate Speech Count')\n",
    "\n",
    "    bloom_count = 0\n",
    "    model_count = 0\n",
    "\n",
    "\n",
    "    #diffeent line and and fig and axis for model and bloom\n",
    "    x_model = np.array([time.time()])\n",
    "    y_model = np.array([0])\n",
    "    line_model, = ax.plot(x_model, y_model)\n",
    "\n",
    "    ax.set_xlim(x_model[0], x_model[0] + 600)\n",
    "    ax.set_ylim(0, 10)\n",
    "\n",
    "    from wordcloud import WordCloud\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    df_speech[\"hate_speech\"] = df_speech[\"lemma\"].apply(detect_hate_speech)\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "\n",
    "        records = consumer.poll(timeout_ms=2000, max_records=500)\n",
    "        print(\"Received {0} messages from topic: {1}\".format(len(records), topic_name))\n",
    "        # Calculate hate speech count per minute\n",
    "        count += 1\n",
    "        for record in records:\n",
    "            for message in records[record]:\n",
    "                decoded_msg = decode_kafka_item(message)\n",
    "                \n",
    "                bloom_start_time = time.time()\n",
    "                is_hate_speech_bloom = detect_hate_speech(decoded_msg)\n",
    "                bloom_end_time = time.time()\n",
    "\n",
    "                print(\"exe : \", bloom_end_time - bloom_start_time)\n",
    "\n",
    "                bloom_execution_total_time += bloom_end_time - bloom_start_time\n",
    "\n",
    "\n",
    "                # model execution\n",
    "                model_start_time = time.time()\n",
    "                predicted_category = pipe(decoded_msg)\n",
    "                label = predicted_category[0]['label']\n",
    "                score = predicted_category[0]['score']\n",
    "\n",
    "                if label in label_to_category and score > 0.5 and label != \"LABEL_0\":\n",
    "                    model_count += 1\n",
    "                model_end_time = time.time()\n",
    "\n",
    "                model_execution_total_time += model_end_time - model_start_time\n",
    "\n",
    "                # create a dataframe\n",
    "                # near real-time / live feed simulation\n",
    "                # creating KPIs\n",
    "                hate_speech_count += is_hate_speech_bloom\n",
    "                bloom_count += is_hate_speech_bloom\n",
    "                avg_bloom_execution_time = bloom_execution_total_time / count\n",
    "                avg_model_execution_time = model_execution_total_time / count\n",
    "\n",
    "\n",
    "                #create kpis for all four categories\n",
    "                if label == \"LABEL_0\":\n",
    "                    acceptable_count += 1\n",
    "                elif label == \"LABEL_1\":\n",
    "                    inappropriate_count += 1\n",
    "                elif label == \"LABEL_2\":\n",
    "                    offensive_count += 1\n",
    "                elif label == \"LABEL_3\":\n",
    "                    violent_count += 1\n",
    "\n",
    "        with placeholder.container():\n",
    "                        \n",
    "            # create kpis\n",
    "            kpi1, accept, inap, off, viol, bloom, model = st.columns(7)\n",
    "\n",
    "            # fill in those three columns with respective metrics or KPIs\n",
    "            kpi1.metric(\n",
    "                label=\"Hate Speech Count (Bloom)\",\n",
    "                value=round(hate_speech_count),\n",
    "                delta=round(hate_speech_count) - 10,\n",
    "            )\n",
    "\n",
    "            accept.metric(\n",
    "                label=\"Acceptable\",\n",
    "                value=round(acceptable_count),\n",
    "                delta=round(acceptable_count) - 10,\n",
    "            )\n",
    "\n",
    "            inap.metric(\n",
    "                label=\"Inappropriate\",\n",
    "                value=round(inappropriate_count),\n",
    "                delta=round(inappropriate_count) - 10,\n",
    "            )\n",
    "\n",
    "            off.metric(\n",
    "                label=\"Offensive\",\n",
    "                value=round(offensive_count),\n",
    "                delta=round(offensive_count) - 10,\n",
    "            )\n",
    "\n",
    "            viol.metric(\n",
    "                label=\"Violent\",\n",
    "                value=round(violent_count),\n",
    "                delta=round(violent_count) - 10,\n",
    "            )\n",
    "\n",
    "            #print in microseconds\n",
    "            bloom.metric(\n",
    "                label=\"Bloom Execution Time (Î¼s)\",\n",
    "                value=round(avg_bloom_execution_time * 1000000, 2),\n",
    "                delta=round(avg_bloom_execution_time - 10, 2),\n",
    "            )\n",
    "\n",
    "            model.metric(\n",
    "                label=\"Model Execution Time (ms)\",\n",
    "                value=round(avg_model_execution_time * 1000, 2),\n",
    "                delta=round(avg_model_execution_time - 10, 2),\n",
    "            )\n",
    "\n",
    "\n",
    "            fig_col1, fig_col2 = st.columns(2)\n",
    "            with fig_col1:\n",
    "                st.markdown(\"### Hate Speech Category Distribution\")\n",
    "                fig = px.bar(\n",
    "                    x=[\"Acceptable\", \"Inappropriate\", \"Offensive\", \"Violent\"],\n",
    "                    y=[acceptable_count, inappropriate_count, offensive_count, violent_count],\n",
    "                    labels={\"x\": \"Category\", \"y\": \"Count\"},\n",
    "                    title=\"Hate Speech Category Distribution\",\n",
    "                )\n",
    "                st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "            with fig_col2:\n",
    "                #heat map\n",
    "                st.markdown(\"### Heat Map of Hate Speech Terms\")\n",
    "                fig = px.density_heatmap(\n",
    "                    df_speech,\n",
    "                    x=\"category\",\n",
    "                    y=\"lemma\",\n",
    "                    title=\"Heat Map of Hate Speech Terms\",\n",
    "                )\n",
    "                st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "            # plot the graph\n",
    "            current_time = time.time()\n",
    "\n",
    "            \n",
    "            if current_time - start_time > 10:\n",
    "                #convert to normal time\n",
    "                x = np.append(x, current_time)\n",
    "                line.set_xdata(x)\n",
    "                #set hate speech count\n",
    "                line.set_ydata(np.append(line.get_ydata(), bloom_count))\n",
    "                the_plot.pyplot(plt)\n",
    "                start_time = current_time\n",
    "                bloom_count = 0\n",
    "\n",
    "            # Create a word cloud\n",
    "            wordcloud = WordCloud(width=800, height=400, random_state=21, max_font_size=110, background_color=\"white\").generate(' '.join(df_speech['lemma']))\n",
    "\n",
    "            # Display the word cloud\n",
    "            st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "            st.title(\"Word Cloud\")\n",
    "            st.image(wordcloud.to_array())\n",
    "                \n",
    "            st.markdown(\"### Detailed Data View\")\n",
    "            st.dataframe(df_speech)\n",
    "            time.sleep(1)\n",
    "\n",
    "read_from_kafka('youtube')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences\n",
    "\n",
    "1. The average execution time for predicting the hate speech using the model is around 50 - 100 ms.\n",
    "2. The average execution time using bloom filter it reduces drastically to 40 - 50 microseconds\n",
    "\n",
    "- The average execution time after applying the Bloom filter is substantially lower than before. This significant reduction indicates the effectiveness of the Bloom filter in speeding up the hate speech prediction process.\n",
    "- The average execution time after applying the Bloom filter is substantially lower than before. This significant reduction indicates the effectiveness of the Bloom filter in speeding up the hate speech prediction process.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "By leveraging the speed and efficiency of Bloom filters, hate speech detection systems can process incoming data streams more quickly, enabling real-time or near-real-time identification of hate speech. This optimization enhances the responsiveness and effectiveness of hate speech moderation efforts, ultimately contributing to a safer online environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
